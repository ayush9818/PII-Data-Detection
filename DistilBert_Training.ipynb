{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cf3ce08c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd \n",
    "import os \n",
    "import json\n",
    "import numpy as np\n",
    "import torch \n",
    "import random \n",
    "\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from spacy.lang.en import English\n",
    "from transformers.trainer import Trainer\n",
    "from transformers.training_args import TrainingArguments\n",
    "from transformers.trainer_utils import EvalPrediction\n",
    "from transformers.data.data_collator import DataCollatorForTokenClassification\n",
    "from datasets import Dataset, DatasetDict, concatenate_datasets\n",
    "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
    "\n",
    "\n",
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    \n",
    "SEED = 23\n",
    "set_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "542220b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data  DebertaV2_Training.ipynb\tDistilBert_Training.ipynb  test\n"
     ]
    }
   ],
   "source": [
    "! ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "14152eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    data_dir = 'data/'\n",
    "    extra_data_dir = 'data/'\n",
    "    train_file_name = 'train.json'\n",
    "    extra_file_name = 'mixtral-8x7b-v1.json'\n",
    "    test_file_name = 'test.json'\n",
    "    TEST_SAMPLES  = 500\n",
    "    TRAINING_MODEL_PATH = \"distilbert/distilbert-base-uncased\"\n",
    "    TRAINING_MAX_LENGTH = 512\n",
    "    EVAL_MAX_LENGTH = 512\n",
    "    FREEZE_EMBEDDINGS = True\n",
    "    FREEZE_LAYERS = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5a9ecb10",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = Config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a6706c19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Data Size : 9162\n",
      "Test Data Size : 10\n"
     ]
    }
   ],
   "source": [
    "train_data1 = json.load(open(os.path.join(cfg.data_dir, cfg.train_file_name)))\n",
    "test_data = json.load(open(os.path.join(cfg.data_dir, cfg.test_file_name)))\n",
    "train_data2 = json.load(open(os.path.join(cfg.extra_data_dir, cfg.extra_file_name)))\n",
    "\n",
    "train_data1 = pd.DataFrame(train_data1)\n",
    "test_data = pd.DataFrame(test_data)\n",
    "train_data2 = pd.DataFrame(train_data2)\n",
    "\n",
    "# Merge train and extra data \n",
    "train_data = pd.concat([train_data1, train_data2])\n",
    "\n",
    "# Update document Id as integer\n",
    "train_data['document'] = [ind+1 for ind in range(len(train_data))]\n",
    "\n",
    "train_data = train_data.reset_index()\n",
    "\n",
    "print(f\"Train Data Size : {train_data.shape[0]}\")\n",
    "print(f\"Test Data Size : {test_data.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4372660c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_no_label_ids(data):\n",
    "    document_ids = []\n",
    "    for idx, row in data.iterrows():\n",
    "        label_list = row['labels']\n",
    "        \n",
    "        if ['O'] * len(label_list) == label_list:\n",
    "            document_ids.append(row['document'])\n",
    "    return document_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "445e3d6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document with no PIL Labels : 5862\n",
      "Document with PIL Labels: 3300\n"
     ]
    }
   ],
   "source": [
    "no_label_doc_ids = get_no_label_ids(data = train_data)\n",
    "with_label_doc_ids = train_data[~train_data.document.isin(no_label_doc_ids)].document.tolist()\n",
    "print(f\"Document with no PIL Labels : {len(no_label_doc_ids)}\\nDocument with PIL Labels: {len(with_label_doc_ids)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e9f94fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_test_df(df, num_samples):\n",
    "    test_df = df.sample(n=num_samples)\n",
    "    train_df = df[~df.document.isin(test_df.document)]\n",
    "    \n",
    "    test_df = test_df.reset_index()\n",
    "    train_df = train_df.reset_index()\n",
    "    return train_df, test_df\n",
    "\n",
    "\n",
    "def split_dataset(data, no_label_ids, with_label_ids, test_samples):\n",
    "    data_no_labels = data[data.document.isin(no_label_ids)]\n",
    "    data_with_labels = data[data.document.isin(with_label_ids)]\n",
    "    \n",
    "    # TEST_SAMPLES // 2 from data_no_labels\n",
    "    # TEST_SAMPLES // 2 from data_with_labels\n",
    "    no_label_train_df , no_label_test_df = sample_test_df(df=data_no_labels, \n",
    "                                                          num_samples=test_samples//2)\n",
    "    with_label_train_df, with_label_test_df = sample_test_df(df=data_with_labels, \n",
    "                                                          num_samples=test_samples//2)\n",
    "    \n",
    "    train_df = pd.concat([with_label_train_df, no_label_train_df])\n",
    "    test_df = pd.concat([with_label_test_df, no_label_test_df])    \n",
    "    return train_df, test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d72ee088",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Data Size : 8662\n",
      "Eval Data Size : 500\n"
     ]
    }
   ],
   "source": [
    "train_df , eval_df = split_dataset(data=train_data,\n",
    "                                   no_label_ids=no_label_doc_ids,\n",
    "                                   with_label_ids=with_label_doc_ids,\n",
    "                                   test_samples=cfg.TEST_SAMPLES\n",
    "                                  )\n",
    "print(f\"Train Data Size : {train_df.shape[0]}\")\n",
    "print(f\"Eval Data Size : {eval_df.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "22371da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_labels = [\n",
    "    'B-EMAIL', 'B-ID_NUM', 'B-NAME_STUDENT', 'B-PHONE_NUM', 'B-STREET_ADDRESS', 'B-URL_PERSONAL', 'B-USERNAME', 'I-ID_NUM', 'I-NAME_STUDENT', 'I-PHONE_NUM', 'I-STREET_ADDRESS', 'I-URL_PERSONAL', 'O'\n",
    "]\n",
    "id2label = {i: l for i, l in enumerate(all_labels)}\n",
    "label2id = {v: k for k, v in id2label.items()}\n",
    "target = [l for l in all_labels if l != \"O\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2c5fc55d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(example, tokenizer, label2id):\n",
    "    # Preprocess the tokens and labels by adding trailing whitespace and labels\n",
    "    tokens = []\n",
    "    labels = []\n",
    "    for token, label, t_ws in zip(example[\"tokens\"], \n",
    "                                  example[\"labels\"],\n",
    "                                  example[\"trailing_whitespace\"]):\n",
    "        tokens.append(token)\n",
    "        labels.extend([label] * len(token))\n",
    "        # Added trailing whitespace and label if true and \n",
    "        if t_ws:\n",
    "            tokens.append(\" \")\n",
    "            labels.append(\"O\")   \n",
    "    text = \"\".join(tokens)\n",
    "    # tokenization without truncation\n",
    "    tokenized = tokenizer(text, return_offsets_mapping=True,\n",
    "                          truncation=True, max_length=cfg.TRAINING_MAX_LENGTH)\n",
    "    labels = np.array(labels)\n",
    "    \n",
    "    # Labels\n",
    "    token_labels = []\n",
    "    for start_idx, end_idx in tokenized.offset_mapping:\n",
    "        # Added 'O' \n",
    "        if start_idx == 0 and end_idx == 0:\n",
    "            token_labels.append(label2id[\"O\"])\n",
    "            continue\n",
    "        \n",
    "        # case when the text starts with whitespace\n",
    "        if text[start_idx].isspace():\n",
    "            start_idx += 1\n",
    "        # Convert label to id (int)\n",
    "        if start_idx< len(labels):\n",
    "            label_id = label2id[labels[start_idx]]\n",
    "            token_labels.append(label_id)\n",
    "    return {**tokenized, \"labels\": token_labels, \"length\": len(tokenized.input_ids)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "12f7d4f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from seqeval.metrics import recall_score, precision_score, f1_score\n",
    "# Compute the model performance metrics using `seqeval`\n",
    "def compute_metrics(preds):    \n",
    "    try:\n",
    "        print(\"Compute metrics\")\n",
    "        predictions, labels = preds\n",
    "        predictions = np.argmax(predictions, axis=2)\n",
    "\n",
    "        # Include prediction Remove ignored index (special tokens)\n",
    "        true_preds = []\n",
    "        true_labels = []\n",
    "        for pred, label in zip(predictions, labels):\n",
    "            true_preds.append([id2label[p] for p, l in zip(pred, label) if l != -100])\n",
    "            true_labels.append([id2label[l] for p, l in zip(pred, label) if l != -100])\n",
    "        # Compute recall, precision and f1 score\n",
    "        recall = recall_score(true_labels, true_preds)\n",
    "        precision = precision_score(true_labels, true_preds)\n",
    "        # Use modified f1 score to measure the performance\n",
    "        f1_score = (1 + 5*5) * recall * precision / (5*5*precision + recall)\n",
    "        result = {'f1': f1_score,  \n",
    "                  'recall': recall,\n",
    "                  'precision': precision}\n",
    "        print(f\"result = {result}\")\n",
    "        del predictions, labels, true_preds, true_labels, preds\n",
    "        return result\n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1eb203f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(cfg.TRAINING_MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6bdffca6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "645ae2367acd4531833cf62495ec05f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/8662 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e03dc3751ada4e6b8b8465c9284c793a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "required_keys = ['tokens', 'trailing_whitespace','labels']\n",
    "train_dict = DatasetDict({key: train_df[key].tolist() for key in required_keys})\n",
    "eval_dict = DatasetDict({key: eval_df[key].tolist() for key in required_keys})\n",
    "train_ds = Dataset.from_dict(train_dict)\n",
    "eval_ds = Dataset.from_dict(eval_dict)\n",
    "\n",
    "\n",
    "\n",
    "max_length = cfg.TRAINING_MAX_LENGTH\n",
    "# To Change \n",
    "train_ds_tokenised = train_ds.map(tokenize, \n",
    "                              fn_kwargs={\"tokenizer\": tokenizer, \n",
    "                                         \"label2id\": label2id},\n",
    "                              num_proc=4)\n",
    "\n",
    "\n",
    "eval_ds_tokenised = eval_ds.map(tokenize, \n",
    "                              fn_kwargs={\"tokenizer\": tokenizer, \n",
    "                                         \"label2id\": label2id},\n",
    "                              num_proc=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "27d4bfbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForTokenClassification were not initialized from the model checkpoint at distilbert/distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForTokenClassification.from_pretrained(cfg.TRAINING_MODEL_PATH, \n",
    "                                                        num_labels=len(all_labels), \n",
    "                                                        id2label=id2label, \n",
    "                                                        label2id=label2id,\n",
    "                                                        ignore_mismatched_sizes=True\n",
    "                                                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0307388d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator=DataCollatorForTokenClassification(tokenizer, pad_to_multiple_of=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "30c96d30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DistilBertForTokenClassification(\n",
       "  (distilbert): DistilBertModel(\n",
       "    (embeddings): Embeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (transformer): Transformer(\n",
       "      (layer): ModuleList(\n",
       "        (0-5): 6 x TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=13, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dfb09c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model.distilbert.embeddings.parameters():\n",
    "    param.requires_grad = cfg.FREEZE_EMBEDDINGS\n",
    "\n",
    "# for layer in model.deberta.encoder.layer[:cfg.FREEZE_LAYERS]:\n",
    "#     for param in layer.parameters():\n",
    "#         param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b0fd421f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "train_args = TrainingArguments(\n",
    "    'test',\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    num_train_epochs=10,\n",
    "    weight_decay=0.01,\n",
    "    report_to=\"none\"\n",
    ")\n",
    "\n",
    "trainer = Trainer(model=model, \n",
    "                  args=train_args, \n",
    "                  data_collator=data_collator,\n",
    "                  train_dataset=train_ds_tokenised,\n",
    "                  eval_dataset=eval_ds_tokenised,\n",
    "                  tokenizer=tokenizer,\n",
    "                  compute_metrics=compute_metrics,\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0b5ecd50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1360' max='1360' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1360/1360 06:13, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Precision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.033993</td>\n",
       "      <td>0.764350</td>\n",
       "      <td>0.762180</td>\n",
       "      <td>0.822912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.008808</td>\n",
       "      <td>0.953198</td>\n",
       "      <td>0.953775</td>\n",
       "      <td>0.938979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.005418</td>\n",
       "      <td>0.967439</td>\n",
       "      <td>0.967039</td>\n",
       "      <td>0.977565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.054700</td>\n",
       "      <td>0.003988</td>\n",
       "      <td>0.982851</td>\n",
       "      <td>0.983060</td>\n",
       "      <td>0.977667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.054700</td>\n",
       "      <td>0.003481</td>\n",
       "      <td>0.987048</td>\n",
       "      <td>0.987262</td>\n",
       "      <td>0.981718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.054700</td>\n",
       "      <td>0.003282</td>\n",
       "      <td>0.988887</td>\n",
       "      <td>0.989232</td>\n",
       "      <td>0.980349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.054700</td>\n",
       "      <td>0.003858</td>\n",
       "      <td>0.989096</td>\n",
       "      <td>0.989626</td>\n",
       "      <td>0.976039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.001800</td>\n",
       "      <td>0.003132</td>\n",
       "      <td>0.989623</td>\n",
       "      <td>0.989888</td>\n",
       "      <td>0.983046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.001800</td>\n",
       "      <td>0.003022</td>\n",
       "      <td>0.990042</td>\n",
       "      <td>0.990282</td>\n",
       "      <td>0.984079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.001800</td>\n",
       "      <td>0.003058</td>\n",
       "      <td>0.989896</td>\n",
       "      <td>0.990151</td>\n",
       "      <td>0.983564</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compute metrics\n",
      "result = {'f1': 0.7643495350203616, 'recall': 0.7621799080761654, 'precision': 0.8229122359279739}\n",
      "Compute metrics\n",
      "result = {'f1': 0.953197718439251, 'recall': 0.9537754432042023, 'precision': 0.9389786683904331}\n",
      "Compute metrics\n",
      "result = {'f1': 0.9674394162944397, 'recall': 0.9670387393302692, 'precision': 0.9775653789990707}\n",
      "Compute metrics\n",
      "result = {'f1': 0.9828512563626082, 'recall': 0.9830597504924491, 'precision': 0.9776674937965261}\n",
      "Compute metrics\n",
      "result = {'f1': 0.9870476132765751, 'recall': 0.9872619829284307, 'precision': 0.9817184643510055}\n",
      "Compute metrics\n",
      "result = {'f1': 0.9888871497886992, 'recall': 0.9892317793827972, 'precision': 0.9803487766788131}\n",
      "Compute metrics\n",
      "result = {'f1': 0.9890961957838623, 'recall': 0.9896257386736704, 'precision': 0.9760393731381946}\n",
      "Compute metrics\n",
      "result = {'f1': 0.9896234656110037, 'recall': 0.9898883782009192, 'precision': 0.9830464267083986}\n",
      "Compute metrics\n",
      "result = {'f1': 0.9900423151112412, 'recall': 0.9902823374917925, 'precision': 0.9840793422941406}\n",
      "Compute metrics\n",
      "result = {'f1': 0.989896031629814, 'recall': 0.990151017728168, 'precision': 0.9835637881554918}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1360, training_loss=0.02104302697321948, metrics={'train_runtime': 377.5736, 'train_samples_per_second': 229.412, 'train_steps_per_second': 3.602, 'total_flos': 1.13194224362496e+16, 'train_loss': 0.02104302697321948, 'epoch': 10.0})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "703942f9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:miniconda3-kg_env]",
   "language": "python",
   "name": "conda-env-miniconda3-kg_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  },
  "vscode": {
   "interpreter": {
    "hash": "e8e432e699936802fa9e748b7bf70380d6e7133e6e6dcc2bbfe590f3ad55f261"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
